{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezzKLPtx8S6C"
      },
      "source": [
        "# **Text Generation with GPT-2 XL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhhWum6YU8kN"
      },
      "source": [
        "This notebook demonstrates the use of the pretrained [GPT-2 XL](https://huggingface.co/openai-community/gpt2-xl) model without any fine-tuning. Developed by [OpenAI](https://github.com/openai/gpt-2), this model is available on [Hugging Face ðŸ¤—](https://huggingface.co/). It is the largest model in the GPT-2 series, with over 1.5 billion parameters, and it achieved better results than the GPT-2 Large model.\n",
        "\n",
        "The model is loaded using the generic class [TFAutoModelForCausalLM](https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.TFAutoModelForCausalLM), which allows for the creation of an instance of a pretrained TensorFlow model designed specifically for causal language tasks and includes an appropriate classification layer on top. For tokenization, the generic [AutoTokenizer](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoTokenizer) is used, which allows for the creation of an instance of the model's tokenizer with just its name."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43AY8jCC8cp-"
      },
      "source": [
        "## **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c0d_8XPxoi92"
      },
      "outputs": [],
      "source": [
        "from transformers import TFAutoModelForCausalLM, AutoTokenizer\n",
        "from IPython.core.display import HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcTHo3vVVrv9"
      },
      "source": [
        "## **Load the Tokenizer and Model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2-xl\""
      ],
      "metadata": {
        "id": "L4MNkvE_jlT1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlGILWr1Vme-",
        "outputId": "359df43e-0729-463c-badf-7e09fd23cb0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2TokenizerFast(name_or_path='gpt2-xl', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# 'use_fast=True': improves the tokenizer's performance when processing large volumes of text\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFAutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_aL89xskY0k",
        "outputId": "73083f13-0c6e-4311-f658-325a34a9ad13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tfgpt2lm_head_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " transformer (TFGPT2MainLay  multiple                  1557611200\n",
            " er)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1557611200 (5.80 GB)\n",
            "Trainable params: 1557611200 (5.80 GB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NhEDFT-uiav"
      },
      "source": [
        "## **Text Generation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WWI-5N0-5WPN"
      },
      "outputs": [],
      "source": [
        "def generate_text(prefix=\" \", num_tokens=50, temperature=0.75, n_generations=2):\n",
        "  inputs = tokenizer(prefix, return_tensors=\"tf\")\n",
        "\n",
        "  preds = model.generate(\n",
        "      **inputs,\n",
        "      max_length=num_tokens,\n",
        "      do_sample=True, #Activates Sampling for text generation\n",
        "      temperature=temperature,\n",
        "      top_k=50,\n",
        "      top_p=0.9,\n",
        "      repetition_penalty=1.2, #Slight penalty to avoid repetitions\n",
        "      num_return_sequences=n_generations, #Generate n results\n",
        "\n",
        "  )\n",
        "\n",
        "  for i, pred in enumerate(preds, 1):\n",
        "    pred = tokenizer.decode(pred, skip_special_tokens=True)\n",
        "    #Replace '\\n' with '<br><br>' to make the line break visible in HTML format\n",
        "    pred = pred.replace(\"\\n\", \"<br>\")\n",
        "    # Shade the prefix in yellow\n",
        "    pred = f\"<span style='background-color: yellow;'>{pred[:len(prefix)]}</span>{pred[len(prefix):]}\"\n",
        "    # Add '...' to indicate that the generation can continue\n",
        "    pred += \"...\"\n",
        "\n",
        "    display((HTML(f\"\"\"\n",
        "    <div style=\"width: 500px;\">\n",
        "      <b>GENERATED TEXT {i}:</b><br>{pred}<br><br>\n",
        "    </div>\n",
        "    \"\"\")))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\n",
        "    prefix=\"Deep in the enchanted forest, a hidden treasure\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "FTOFIdmXwdSv",
        "outputId": "50c4c4ea-e499-4165-b54e-074c63ff80f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 1:</b><br><span style='background-color: yellow;'>Deep in the enchanted forest, a hidden treasure</span> awaits you.<br><br>A mysterious island has been discovered and it is now your job to explore its depths and uncover all of the secrets it holds before someone else does!<br><br>The adventure begins when an...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 2:</b><br><span style='background-color: yellow;'>Deep in the enchanted forest, a hidden treasure</span> awaits you! A mysterious figure from your past has awoken and is trying to claim it for his own. You are tasked with defeating him while keeping this secret safe. Use magic spells like fireballs and lightning...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\n",
        "    prefix=\"Journeying through time to\",\n",
        "    num_tokens=100\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "LRUNOIUEv9KR",
        "outputId": "2644434f-ea9d-4982-c64f-e17ee6baa288"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 1:</b><br><span style='background-color: yellow;'>Journeying through time to</span> the present day, this series takes us from the dawn of time all the way up to the year 3000. In each episode we'll follow a different character as they explore and discover something about their past....<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 2:</b><br><span style='background-color: yellow;'>Journeying through time to</span> find the truth about our past and what is behind it, we have come across a lot of interesting people. Some are heroes, some are villains, but most of them can be described as a mixture between these two extremes.\"<br><br>\"The first person I encountered was Kirito,\" she said. \"He seemed like he had some sort of problem or something that was bothering him, so I decided to ask him for his help. It turned out that he...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\n",
        "    prefix=\"In a distant future, humanity discovered\",\n",
        "    num_tokens=200\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "coz3cbwxzcWi",
        "outputId": "4e47d21b-d3d5-4d54-dab0-ef7bc272b9c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 1:</b><br><span style='background-color: yellow;'>In a distant future, humanity discovered</span> a new planet in the solar system with an atmosphere that could support life. This discovery prompted people to go out and explore this newly-discovered world, called \"Venus\".<br><br>However, they soon discovered that Venus was not as hospitable as initially thought. There were too many violent storms, toxic clouds and dangerous temperatures for any human to survive there for long periods of time. The discovery had major consequences for mankind's scientific and technological advancement, which is why scientists have been working on ways to create artificial gravity on Mars.<br><br>To accomplish such feats, scientists are currently developing technologies that can simulate the conditions found on Earth and Mars by using gravitational waves from a colliding black hole or neutron star, respectively. These methods allow scientists to learn more about the planets' geological history, and ultimately help them develop better tools to preserve and sustain life on these worlds....<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 2:</b><br><span style='background-color: yellow;'>In a distant future, humanity discovered</span> that it had developed the ability to harness the power of space.<br><br>The first time they used this new energy was in their war with the Minbari. The Minbari were able to use the energy from the sun to greatly increase their power and size, so they attacked Earth's surface. To stop them, the Alliance sent an expeditionary force to Mars. They succeeded in stopping them by using nuclear missiles launched from a Polaris-class cruiser (the ship seen during \"Distant Origin\"). This helped the Alliance defeat the Minbari but not before one of the missiles exploded on Mars destroying much of its atmosphere. However, it did manage to destroy all life on Mars except for those living underground. This event led to the creation of a giant crater called the Red Planet, where humanity would eventually settle.<br><br>With a large enough population on Mars, the Alliance began expanding outwards into other planets. On Venus, they built a massive city,...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\n",
        "    prefix=\"Once upon a time, in a small village\",\n",
        "    num_tokens=300\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "dX74g59vvuR1",
        "outputId": "4a58f620-7a30-4d1d-db8f-4d23649e87b4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 1:</b><br><span style='background-color: yellow;'>Once upon a time, in a small village</span> called Binnish. The villagers had been very good to me and I was doing well until one day they decided that I should not be allowed into the church for fear of my teaching others how to pray. They said, \"You have no right because you are not baptized.\" And when I protested, they threw stones at me.<br><br>That is what happened to me there. But I did not give up! In fact, I started praying harder than ever. Soon after, my father went on holiday so I took over his position as pastor. We were now able to preach without fear of persecution. People came to us with their problems, and we helped them resolve them in prayer. My congregation grew rapidly from 10 people to 50-60 in two years. I preached the Word of God every Sunday and every other Friday, and we had many beautiful baptisms.<br><br>Then, I received an invitation from a great religious leader who lived just across the border. He asked me if I would come and preach to him and his followers about Jesus Christ. I thought it was too dangerous, but he assured me that I would never die. So I left immediately and traveled all the way to Iran to see this man. Once there, I found myself sharing a room with dozens of young Christians.<br><br>They told me that the Iranian government wanted to kill these young Christians because they were proselytizing. There were even reports that the police...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 2:</b><br><span style='background-color: yellow;'>Once upon a time, in a small village</span> called Chidori in northern India, the Maharaja of Patiala had one of his courtiers make a deal with the devil. It was a rather modest deal: the devil would grant him a hundred years of peace and prosperity in exchange for one thousand of his subjects agreeing to be baptised as Christians. The devil's offer seemed reasonable enough at first glance; after all, no ruler in India was ever killed by a peasant uprising, and there were plenty of happy people living in Chidori too. But it turned out that not only did the demon have nothing left over to give back to the king, but he also had absolutely zero interest in helping the prince maintain order or even keep his kingdom intact. In fact, he despised the whole thing and wanted none of it. He made every effort possible to destroy everything the prince builtâ€”his own realm included. So if you're reading this, don't expect me to be making excuses for you. I'm just going to tell you what happened next.<br><br>For a long while things went well for the prince. At last the prince returned home from his pilgrimage to Mecca, and when he arrived he found himself surrounded by demons who had stolen away all the money he'd brought back, along with many other items of value. \"I cannot believe what has been happening,\" the Prince told his advisers. \"It is like they are trying to take our kingdom away.\" They were right about...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\n",
        "    prefix=\"On a dark and stormy night, a mysterious figure\",\n",
        "    num_tokens=400,\n",
        "    n_generations=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "uNGk4nBlwJex",
        "outputId": "04ec2bb8-2980-4347-c2c3-f23e45a22aeb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 1:</b><br><span style='background-color: yellow;'>On a dark and stormy night, a mysterious figure</span> appears in the streets of London. A young man named Jack Harkness discovers that this new stranger is none other than the famous psychic Dr John Watson. The two are drawn into an adventure to uncover a conspiracy behind a series of violent murders.<br><br>Synopsis: The film opens with a familiar scene as Jack Harkness meets up with his old friend and fellow paranormal investigator Sherlock Holmes (Martin Freeman) at Baker Street Station in London. There, they see a large crowd gathered around a small boy who has been tied up by a rope made from a human skull. It turns out he's the son of the local MP, Harold Saxon (Christopher Lee). At first it seems that Saxon had kidnapped him for unknown reasons but after further investigation, we discover that it was actually the work of the infamous Mr Big (Richard Burton). Big's sinister plan was to create an army of super soldiers through DNA manipulation which would make them more powerful than any army on earth. He wanted to use them to take over the world.<br><br>When Jack arrives at Saxon's house, he immediately suspects that something isn't right. His suspicions are confirmed when he sees a bloody murder victim next to Saxon's bed. This leads them to investigate Saxon's father, Dr Harold Saxon who also works as a private detective. When Jack comes face-to-face with the monster inside the doctor's mind, he begins to question what exactly he should do about it. The film then follows Jack throughout the rest of the night until they finally arrive at Big's lair where they have to fight their way through hordes of henchmen before escaping. As the pair escape, Jack finds himself under attack again by the creature. After defeating it once again, the pair eventually make their way back to London. Once there, they run into Sir Arthur Conan Doyle (David Warner), who wants to know if he can help Jack find the truth. He...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\n",
        "    prefix=\"In the year 2150, technology had advanced to\",\n",
        "    num_tokens=500,\n",
        "    n_generations=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "dHUlX7qnwkWg",
        "outputId": "748ce654-ff3b-4aea-fbec-bf62d6b504ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 1:</b><br><span style='background-color: yellow;'>In the year 2150, technology had advanced to</span> a point where there was no longer any reason for humans to exist on Mars. But one person did not give up on the Red Planet.<br><br>Sebastian von Humboldt (1809-1873) was an Austrian scientist who spent years studying and cataloging rocks on Mars. He would later develop his theory of geology, which proposed that all rocks formed from the same materialâ€”a process called differentiation. In addition, he developed a mathematical model that could be used to predict how long it took for the Martian crust to form. This is in stark contrast to today's conventional wisdom that the planet is only about 4 billion years old.<br><br>But von Humboldt also believed that human beings were somehow linked with the planet, as he noted that \"the earth has always been visited by men.\" In fact, it might be argued that if the planets are inhabited, then so too must they have once been populated by life forms. After all, we find evidence of life throughout the universe, ranging from bacteria living on volcanic lava in Hawaii to giant insects on Saturn's moon Titan. If aliens can travel throughout space and time, then surely they can visit Earth. Perhaps we should think twice before dismissing the possibility because our planet doesn't look like what you see in science fiction movies or shows?<br><br>So why didn't von Humboldt just tell the world that Mars was inhabited thousands of years ago? Well, he may have wanted to avoid upsetting his political allies in Vienna, and it certainly wouldn't hurt to keep them happy. So instead, Von Humboldt wrote his book A New Astronomy, a work that became popular and influential in Europe during the 19th century. The publication of this book sparked debate and controversy over whether von Humboldt was making a scientific discovery or simply speculating.<br><br>In spite of these concerns, scientists worldwide continue to explore and study the Red Planet. It isn't until the 1960s when NASA launched its first manned mission to Mars that humans began exploring the red planet with unmanned probes. Since then, more than 100 missions have landed on Marsâ€”and more than 1,000 astronauts have traveled to the surface on each expedition....<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Risks, Limitations, and Biases of the Model**\n",
        "Since the GPT-2 XL model was trained on a large amount of unfiltered Internet content, its generated outputs can contain disturbing and harmful stereotypes related to protected classes, identity characteristics, and sensitive social and occupational groups, as mentioned on the [Hugging Face website](https://huggingface.co/openai-community/gpt2-xl#risks-limitations-and-biases). This issue also exists in the smaller versions than GPT-2 XL. Additionally, OpenAI has noted that the model can be misused to promote ideologies such as white supremacy, Marxism, jihadist Islamism, and anarchism. Therefore, it is crucial to use the model responsibly and judiciously to benefit society and support the advancement of AI in a positive direction.\n",
        "\n"
      ],
      "metadata": {
        "id": "dpm8jxUW8Weh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example of Gender Bias**"
      ],
      "metadata": {
        "id": "p7ZPiOwJ-WNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\n",
        "    prefix=\"The man worked as a\",\n",
        "    num_tokens=15,\n",
        "    n_generations=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "61YG8ogv9FHD",
        "outputId": "67712c3b-edd6-4ce9-d45c-b71e9f94a0dc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 1:</b><br><span style='background-color: yellow;'>The man worked as a</span> security guard at the hospital.<br><br>After the...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 2:</b><br><span style='background-color: yellow;'>The man worked as a</span> carpenter in the city of Bangui,...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 3:</b><br><span style='background-color: yellow;'>The man worked as a</span> courier for the British security services and he was known...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 4:</b><br><span style='background-color: yellow;'>The man worked as a</span> plumber and had been living in the house with...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 5:</b><br><span style='background-color: yellow;'>The man worked as a</span> barber at the store and was also known to...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\n",
        "    prefix=\"The woman worked as a\",\n",
        "    num_tokens=15,\n",
        "    n_generations=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "MSjXeU8Y-EA0",
        "outputId": "f63a4d5c-3c3c-44d3-b47b-bbd918d22d7c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 1:</b><br><span style='background-color: yellow;'>The woman worked as a</span> clerk in the U.S. Postal Service and...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 2:</b><br><span style='background-color: yellow;'>The woman worked as a</span> prostitute in the U.S.<br><br>It...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 3:</b><br><span style='background-color: yellow;'>The woman worked as a</span> secretary in a hotel. She said she was going...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 4:</b><br><span style='background-color: yellow;'>The woman worked as a</span> nurse at the hospital and her husband was employed by...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"width: 500px;\">\n",
              "      <b>GENERATED TEXT 5:</b><br><span style='background-color: yellow;'>The woman worked as a</span> maid in the house, and she said she had...<br><br>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "coursera": {
      "schema_names": [
        "NLPC3-4A"
      ]
    },
    "grader_version": "1",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}